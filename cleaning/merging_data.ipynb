{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Load the CSV files\n",
    "tm_values = pd.read_csv('../data/tm/processed/tm_values.csv')\n",
    "player_stats = pd.read_csv('../data/fbref/engineered/outfield-goalkeeper-combined/fbref__outfield_player_goalkeeper_stats_combined_latest.csv')\n",
    "mapping_data = pd.read_csv('../data/mapping/fbref_to_tm_mapping.csv', encoding='ISO-8859-1')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete entries from season 2021/2022 from fbref data\n",
    "player_stats = player_stats[player_stats['Season'] != '2021-2022']\n",
    "\n",
    "# Filter the DataFrame by position\n",
    "gk_stats = player_stats[player_stats['Pos'] == 'GK']\n",
    "out_stats = player_stats[player_stats['Pos'] != 'GK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30618/2585269126.py:40: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  gk_stats = gk_stats.groupby(['Player', 'Born']).apply(consolidate_season_data).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Function to consolidate duplicate rows for each player in each season\n",
    "def consolidate_season_data(player_data):\n",
    "    # Identify all unique seasons for the player\n",
    "    unique_seasons = player_data['Season'].unique()\n",
    "\n",
    "    # Create an empty DataFrame to store the consolidated data\n",
    "    consolidated_data = pd.DataFrame()\n",
    "\n",
    "    for season in unique_seasons:\n",
    "        # Filter the data for the current season\n",
    "        season_data = player_data[player_data['Season'] == season]\n",
    "\n",
    "        # Group the data by club\n",
    "        clubs = season_data['Squad'].unique()\n",
    "\n",
    "        for club in clubs:\n",
    "            # Filter the data for the current club\n",
    "            club_data = season_data[season_data['Squad'] == club]\n",
    "\n",
    "            if len(club_data) == 2:  # There should be two duplicated rows\n",
    "                # Select the relevant parts of each row\n",
    "                part_1 = club_data.iloc[0, :division_index]  # Data up to the 'GA' column\n",
    "                part_2 = club_data.iloc[1, division_index:]  # Data from the 'GA' column onwards\n",
    "\n",
    "                # Combine the two parts into a single row\n",
    "                combined_row = pd.concat([part_1, part_2])\n",
    "                # Append the combined row to the consolidated DataFrame\n",
    "                consolidated_data = pd.concat([consolidated_data, combined_row.to_frame().T], ignore_index=True)\n",
    "            else:\n",
    "                # If there is no duplication (or some other unexpected case), keep the data as is\n",
    "                consolidated_data = pd.concat([consolidated_data, club_data], ignore_index=True)\n",
    "\n",
    "    return consolidated_data\n",
    "\n",
    "# Identify the index of the 'GA' column\n",
    "division_column = 'GA'\n",
    "division_index = gk_stats.columns.get_loc(division_column)\n",
    "\n",
    "# Apply the function to consolidate data for each player\n",
    "gk_stats = gk_stats.groupby(['Player', 'Born']).apply(consolidate_season_data).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Get the list of all columns\n",
    "all_columns = player_stats.columns.tolist()\n",
    "\n",
    "# Find the index of the columns for goalkeepers and outfield players\n",
    "start_index_out = all_columns.index('Gls') # +1 to exclude 'Matches'\n",
    "end_index_out = all_columns.index('Position Grouped') + 1  # +1 to include 'League Name'\n",
    "\n",
    "# Select the desired columns for goalkeepers\n",
    "# Select the desired columns for outfield players\n",
    "out_columns = ['Player', 'Nation', 'Pos', 'Squad', 'Comp', 'Age', 'Born', 'MP', 'Starts', 'Min', '90s'] + all_columns[start_index_out:end_index_out]\n",
    "\n",
    "# Filter the DataFrame for outfield players and select the desired columns\n",
    "out_stats = out_stats[out_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_player_stats(df, num_seasons=4, min_minutes=350):\n",
    "    # Create a copy of the DataFrame\n",
    "    df = df.copy()\n",
    "\n",
    "    # Step 0: Normalize the Season format from '2017-2018' to '2017/2018'\n",
    "    df['Season'] = df['Season'].apply(lambda x: x.replace('-', '/') if isinstance(x, str) else x)\n",
    "\n",
    "    # Create a composite key to uniquely identify each player\n",
    "    df['Composite Key'] = df['Player'] + df['Born'].astype(str)\n",
    "\n",
    "    # Step 1: Filter to keep the row with more minutes for the same season\n",
    "    df = df.sort_values('Min', ascending=False).drop_duplicates(['Season', 'Composite Key'], keep='first')\n",
    "\n",
    "    # Step 2: Ensure the player has data for all seasons\n",
    "    season_counts = df['Composite Key'].value_counts()\n",
    "    df = df[df['Composite Key'].isin(season_counts[season_counts >= num_seasons].index)]\n",
    "\n",
    "    # Step 3: Ensure the player has at least one season with 350+ minutes\n",
    "    def has_high_minutes(group):\n",
    "        return any(group['Min'] >= min_minutes)\n",
    "    df = df.groupby('Composite Key').filter(has_high_minutes)\n",
    "\n",
    "    # Step 4: Ensure Age follows a sequential order\n",
    "    # Sort by Player and Season\n",
    "    df.sort_values(['Player', 'Season'], inplace=True)\n",
    "    df['Age_diff'] = df.groupby('Composite Key')['Age'].diff()\n",
    "    non_sequential = df[(df['Age_diff'] != 1) & (~df['Age_diff'].isnull())]['Composite Key'].unique()\n",
    "    df = df[~df['Composite Key'].isin(non_sequential)]\n",
    "\n",
    "    # Step 5: Validate players' Born year consistency\n",
    "    valid_born = df.groupby('Composite Key')['Born'].nunique()\n",
    "    valid_born = valid_born[valid_born == 1].index\n",
    "    df = df[df['Composite Key'].isin(valid_born)]\n",
    "\n",
    "    # Step 6: Fix encoding issues in Player and Squad names\n",
    "    def fix_encoding_issues(name):\n",
    "        try:\n",
    "            return name.encode('latin1').decode('utf-8')\n",
    "        except (UnicodeEncodeError, UnicodeDecodeError):\n",
    "            return name\n",
    "\n",
    "    df['Player'] = df['Player'].apply(fix_encoding_issues)\n",
    "    df['Squad'] = df['Squad'].apply(fix_encoding_issues)\n",
    "\n",
    "    # Drop the Composite Key and Age_diff columns as they are no longer needed\n",
    "    df = df.drop(columns=['Composite Key', 'Age_diff'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the integrated function to both goalkeepers and outfield players\n",
    "filtered_gk_stats = process_player_stats(gk_stats)\n",
    "filtered_out_stats = process_player_stats(out_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'Player' name for 'Marcelo' born in 1988 to 'Marcelo Junior'\n",
    "filtered_out_stats.loc[(filtered_out_stats['Player'] == 'Marcelo') &\n",
    "                       (filtered_out_stats['Born'] == 1988.0), 'Player'] = 'Marcelo Júnior'\n",
    "\n",
    "# Update 'Player' name for 'Raul Garcia' born in 1989 to 'Raul Carnero'\n",
    "filtered_out_stats.loc[(filtered_out_stats['Player'] == 'Raúl García') &\n",
    "                       (filtered_out_stats['Born'] == 1989.0), 'Player'] = 'Raúl Carnero'\n",
    "\n",
    "# Update 'Player' name for José Luis Gayà\n",
    "filtered_out_stats.loc[(filtered_out_stats['Player'] == 'JosÃ© Luis GayÃ'), 'Player'] = 'José Luis Gayà'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30618/1480683103.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  season_values = tm_values_sorted.groupby(['player_id', 'season']).apply(select_market_values).reset_index()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert date column to datetime\n",
    "tm_values['date'] = pd.to_datetime(tm_values['date'])\n",
    "\n",
    "# Function to determine season based on date\n",
    "def get_season(date):\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    if year == 2017 and month in [5, 6]:\n",
    "        return '2017/2018'\n",
    "    elif month >= 7:\n",
    "        return f\"{year}/{year+1}\"\n",
    "    else:\n",
    "        return f\"{year-1}/{year}\"\n",
    "\n",
    "# Apply the season function\n",
    "tm_values['season'] = tm_values['date'].apply(get_season)\n",
    "\n",
    "# Sort by player_id, season, and date\n",
    "tm_values_sorted = tm_values.sort_values(['player_id', 'season', 'date']).reset_index(drop=True)\n",
    "\n",
    "# Function to get the first and last market values for each season, preserving player_name and club\n",
    "def select_market_values(df):\n",
    "    first_value = df.iloc[0]['market_value']\n",
    "    last_value = df.iloc[-1]['market_value']\n",
    "    position = df.iloc[0]['position']\n",
    "    player_name = df.iloc[0]['player_name']  # Preserve player_name\n",
    "    club = df.iloc[-1]['club']  # Keep the club corresponding to the last market value\n",
    "    return pd.Series({\n",
    "        'player_name': player_name,\n",
    "        'club': club,\n",
    "        'market_value_1': first_value,\n",
    "        'market_value_2': last_value,\n",
    "        'position': position\n",
    "    })\n",
    "\n",
    "# Apply the function to group by player_id and season\n",
    "season_values = tm_values_sorted.groupby(['player_id', 'season']).apply(select_market_values).reset_index()\n",
    "\n",
    "# Manually update the 2020/2021 season with the first value from 2021/2022\n",
    "for idx in range(len(season_values) - 1):\n",
    "    if season_values.at[idx, 'season'] == '2020/2021':\n",
    "        next_season_value = season_values.at[idx + 1, 'market_value_1']\n",
    "        if season_values.at[idx + 1, 'season'] == '2021/2022':\n",
    "            season_values.at[idx, 'market_value_2'] = next_season_value\n",
    "\n",
    "# Ensure that the 2021/2022 season is completely excluded\n",
    "filtered_season_values = season_values[season_values['season'] != '2021/2022']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_encoding_issues(name):\n",
    "        try:\n",
    "            return name.encode('latin1').decode('utf-8')\n",
    "        except (UnicodeEncodeError, UnicodeDecodeError):\n",
    "            return name\n",
    "\n",
    "mapping_data['PlayerFBref'] = mapping_data['PlayerFBref'].apply(fix_encoding_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract player_id\n",
    "def extract_player_id(url):\n",
    "    try:\n",
    "        # Attempt to split and convert to integer\n",
    "        return int(url.split('/')[-1])\n",
    "    except ValueError:\n",
    "        # Return None if it fails\n",
    "        return None\n",
    "\n",
    "# Apply the function to extract player_id\n",
    "mapping_data['player_id'] = mapping_data['UrlTmarkt'].apply(extract_player_id)\n",
    "\n",
    "# Drop rows where player_id is None\n",
    "mapping_data = mapping_data.dropna(subset=['player_id'])\n",
    "\n",
    "# Convert player_id to integer type\n",
    "mapping_data['player_id'] = mapping_data['player_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_exclude = [229736, 627231, 291968, 646658, 385271, 565232, 257097, 479647, 519731, 808509, 738498, 870414, 704558,\n",
    "                  627230, 75081, 442818, 471474, 227085, 232142, 155470, 461906, 626724, 235568, 342024, 746908, 250144,\n",
    "                  573907, 277118, 910216, 697818, 54155, 538234, 406675, 443721, 516722, 668268, 54132, 582301, 127554,\n",
    "                  231289, 817665, 848479, 148765, 432895, 428787, 531916, 498235, 33947, 52894, 1053934, 187099, 170385,\n",
    "                  820227, 117549, 630995, 743593, 631785, 175256, 1012158, 583607, 153207, 55338, 252900]\n",
    "\n",
    "ids_to_name = {44501: 'Marcelo Júnior', 139434: 'Raúl Carnero'}\n",
    "\n",
    "# Filter out the players to exclude\n",
    "mapping_data = mapping_data[~mapping_data['player_id'].isin(ids_to_exclude)]\n",
    "\n",
    "# Update player names based on the player_id using the map function\n",
    "mapping_data['PlayerFBref'] = mapping_data['player_id'].map(ids_to_name).fillna(mapping_data['PlayerFBref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge filtered_out_stats with mapping_data to get player_id\n",
    "merged_out_stats_with_ids = pd.merge(filtered_out_stats, mapping_data[['PlayerFBref', 'player_id']],\n",
    "                                     left_on='Player', right_on='PlayerFBref', how='left')\n",
    "\n",
    "# Merge the outfield stats with the market value data\n",
    "final_merged_out_stats = pd.merge(merged_out_stats_with_ids, filtered_season_values[['market_value_1', 'market_value_2', 'season', 'player_id', 'position']],\n",
    "                                  left_on=['Season', 'player_id'], right_on=['season', 'player_id'], how='left')\n",
    "\n",
    "# Clean up unnecessary columns\n",
    "final_merged_out_stats = final_merged_out_stats.drop(columns=['PlayerFBref', 'season'])\n",
    "\n",
    "# Merge filtered_gk_stats with mapping_data to get player_id\n",
    "merged_gk_stats_with_ids = pd.merge(filtered_gk_stats, mapping_data[['PlayerFBref', 'player_id']],\n",
    "                                    left_on='Player', right_on='PlayerFBref', how='left')\n",
    "\n",
    "# Merge the goalkeeper stats with the market value data\n",
    "final_merged_gk_stats = pd.merge(merged_gk_stats_with_ids, filtered_season_values[['market_value_1', 'market_value_2', 'season', 'player_id', 'position']],\n",
    "                                  left_on=['Season', 'player_id'], right_on=['season', 'player_id'], how='left')\n",
    "\n",
    "# Clean up unnecessary columns\n",
    "final_merged_gk_stats = final_merged_gk_stats.drop(columns=['PlayerFBref', 'season'])\n",
    "\n",
    "# Filter out players who have any NaN values in market_value_1 or market_value_2\n",
    "players_with_nan_values = final_merged_out_stats[final_merged_out_stats[['market_value_1', 'market_value_2']].isna().any(axis=1)]['Player'].unique()\n",
    "\n",
    "# Remove all records of these players from the final_merged_out_stats DataFrame\n",
    "final_merged_out_stats = final_merged_out_stats[~final_merged_out_stats['Player'].isin(players_with_nan_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_map = {\n",
    "    'Defender - Centre-Back': 'Centre-Back',\n",
    "    'Defender - Left-Back': 'Wing-Back',\n",
    "    'Defender - Right-Back': 'Wing-Back',\n",
    "    'midfield - Defensive Midfield': 'Defensive Midfielder',\n",
    "    'midfield - Central Midfield': 'Central Midfielder',\n",
    "    'midfield - Attacking Midfield': 'Attacking Midfielder',\n",
    "    'attack - Second Striker': 'Attacking Midfielder',\n",
    "    'midfield - Left Midfield': 'Winger',\n",
    "    'midfield - Right Midfield': 'Winger',\n",
    "    'attack - Left Winger': 'Winger',\n",
    "    'attack - Right Winger': 'Winger',\n",
    "    'attack - Centre-Forward': 'Centre-Forward'\n",
    "}\n",
    "\n",
    "position_missing_map = {\n",
    "    'Alessio Romagnoli': 'Centre-Back',\n",
    "    'Carlos Bacca': 'Centre-Forward',\n",
    "    'Dani Carvajal': 'Wing-Back',\n",
    "    'Facundo Roncaglia': 'Centre-Back',\n",
    "    'José Campaña': 'Central Midfielder',\n",
    "    'José Ángel': 'Wing-Back',\n",
    "    'Marcelo Júnior': 'Wing-Back',\n",
    "    'Mário Rui': 'Wing-Back',\n",
    "    'Rúben Vezo': 'Centre-Back',\n",
    "    'Sebastien De Maio': 'Centre-Back'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'position' column\n",
    "final_merged_out_stats['Position'] = final_merged_out_stats['position'].map(position_map)\n",
    "final_merged_out_stats['Position'] = final_merged_out_stats['Player'].map(position_missing_map).fillna(final_merged_out_stats['Position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame\n",
    "final_out_stats_filtered = final_merged_out_stats.copy()\n",
    "\n",
    "# Renaming columns\n",
    "final_out_stats_filtered.rename(columns={\n",
    "    'player_id': 'ID',\n",
    "    'Squad': 'Team',\n",
    "    'Nationality Cleaned': 'Nationality',\n",
    "    'market_value_1': 'MV1',\n",
    "    'market_value_2': 'MV2',\n",
    "    'G-PK': 'npG',\n",
    "    'G-PK.1': 'npG/90',\n",
    "    'np:G-xG' : 'npG-npxG',\n",
    "    'Cmp': 'PassCmp',\n",
    "    'Att': 'PassAtt',\n",
    "    'Cmp%': 'Pass%',\n",
    "    'Prog': 'PrgPass',\n",
    "    'Prog.1': 'PrgPassRec',\n",
    "    'SCA90': 'SCA/90',\n",
    "    'GCA90': 'GCA/90',\n",
    "    'Succ': 'PressSucc',\n",
    "    '%': 'Press%',\n",
    "    'Succ%': 'Drib%',\n",
    "    '#Pl': 'DribSucc',\n",
    "    'Won': 'ADuelWon',\n",
    "    'Won%': 'ADuel%'},\n",
    "                                inplace=True)\n",
    "\n",
    "# Creating new columns using .loc\n",
    "final_out_stats_filtered.loc[:, 'DribSucc/90'] = (final_out_stats_filtered['DribSucc'] / final_out_stats_filtered['90s']).round(2)\n",
    "final_out_stats_filtered.loc[:, 'PassCmp/90'] = (final_out_stats_filtered['PassCmp'] / final_out_stats_filtered['90s']).round(2)\n",
    "final_out_stats_filtered.loc[:, 'PassAtt/90'] = (final_out_stats_filtered['PassAtt'] / final_out_stats_filtered['90s']).round(2)\n",
    "final_out_stats_filtered.loc[:, 'PrgPass/90'] = (final_out_stats_filtered['PrgPass'] / final_out_stats_filtered['90s']).round(2)\n",
    "final_out_stats_filtered.loc[:, 'PrgPassRec/90'] = (final_out_stats_filtered['PrgPassRec'] / final_out_stats_filtered['90s']).round(2)\n",
    "final_out_stats_filtered.loc[:, 'Tkl/90'] = (final_out_stats_filtered['Tkl'] / final_out_stats_filtered['90s']).round(2)\n",
    "final_out_stats_filtered.loc[:, 'TklW/90'] = (final_out_stats_filtered['TklW'] / final_out_stats_filtered['90s']).round(2)\n",
    "final_out_stats_filtered.loc[:, 'Int'] = (final_out_stats_filtered['Tkl+Int'] - final_out_stats_filtered['Tkl'])\n",
    "final_out_stats_filtered.loc[:, 'Int/90'] = (final_out_stats_filtered['Int'] / final_out_stats_filtered['90s']).round(2)\n",
    "final_out_stats_filtered.loc[:, 'Clr/90'] = (final_out_stats_filtered['Clr'] / final_out_stats_filtered['90s']).round(2)\n",
    "final_out_stats_filtered.loc[:, 'Recov/90'] = (final_out_stats_filtered['Recov'] / final_out_stats_filtered['90s']).round(2)\n",
    "final_out_stats_filtered.loc[:, 'Touches/90'] = (final_out_stats_filtered['Touches'] / final_out_stats_filtered['90s']).round(2)\n",
    "final_out_stats_filtered.loc[:, 'PressSucc/90'] = (final_out_stats_filtered['PressSucc'] / final_out_stats_filtered['90s']).round(2)\n",
    "final_out_stats_filtered.loc[:, 'ADuelWon/90'] = (final_out_stats_filtered['ADuelWon'] / final_out_stats_filtered['90s']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep for the final output\n",
    "columns_to_keep = [\n",
    "    'ID', 'Player', 'Team', 'Age', 'Nationality', 'Season', 'MV1', 'MV2',\n",
    "    'Position', 'Pos', 'Comp', 'MP', 'Starts', 'Min', '90s',\n",
    "    'npG', 'npG/90', 'npG-npxG', 'Sh', 'SoT', 'SoT%', 'Sh/90', 'SoT/90',\n",
    "    'SCA', 'GCA', 'SCA/90', 'GCA/90', 'DribSucc', 'DribSucc/90', 'Drib%',\n",
    "    'PassCmp', 'PassCmp/90', 'PassAtt', 'PassAtt/90', 'Pass%', 'PrgPass', 'PrgPass/90', 'PrgPassRec', 'PrgPassRec/90',\n",
    "    'Tkl', 'Tkl/90', 'TklW', 'TklW/90', 'Int', 'Int/90', 'Clr', 'Clr/90', 'Recov', 'Recov/90',\n",
    "    'PressSucc', 'PressSucc/90', 'Press%', 'ADuelWon', 'ADuelWon/90', 'ADuel%',\n",
    "    'Touches', 'Touches/90', 'PPM', 'On-Off']\n",
    "\n",
    "# Filter the columns to keep\n",
    "final_out_stats_filtered = final_out_stats_filtered[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame\n",
    "final_gk_stats_filtered = final_merged_gk_stats.copy()\n",
    "\n",
    "# Renaming columns\n",
    "final_gk_stats_filtered.rename(columns={\n",
    "    'player_id': 'ID',\n",
    "    'Squad': 'Team',\n",
    "    'Nationality Cleaned': 'Nationality',\n",
    "    'Position Grouped': 'Position',\n",
    "    'market_value_1': 'MV1',\n",
    "    'market_value_2': 'MV2',\n",
    "    'GA90': 'GA/90',\n",
    "    'Save%.1': 'PKSave%',\n",
    "    'PSxG+/-': 'PSxG-GA',\n",
    "    '/90': 'PSxG-GA/90',\n",
    "    'Opp': 'CrossAtt',\n",
    "    'PKA': 'PKAtt',\n",
    "    'Cmp%': 'Pass%',\n",
    "    'Cmp%.3': 'LPass%',\n",
    "    '#OPA': 'ActOutPA',\n",
    "    '#OPA/90': 'ActOutPA/90',\n",
    "    'Stp%': 'CrossStop%',\n",
    "    'Att.2': 'SPassAtt',\n",
    "    'Cmp.2': 'SPassCmp',\n",
    "    'Cmp%.2': 'SPass%',\n",
    "    'Att.3': 'LPassAtt',\n",
    "    'Cmp.3': 'LPassCmp',\n",
    "    'Cmp%.3': 'LPass%'\n",
    "    },\n",
    "                                inplace=True)\n",
    "\n",
    "# Creating new columns using .loc\n",
    "final_gk_stats_filtered.loc[:, 'SoTA/90'] = (final_gk_stats_filtered['SoTA'] / final_gk_stats_filtered['90s']).round(2)\n",
    "final_gk_stats_filtered.loc[:, 'CrossAtt/90'] = (final_gk_stats_filtered['CrossAtt'] / final_gk_stats_filtered['90s']).round(2)\n",
    "final_gk_stats_filtered.loc[:, 'PKAtt/90'] = (final_gk_stats_filtered['PKAtt'] / final_gk_stats_filtered['90s']).round(2)\n",
    "final_gk_stats_filtered.loc[:, 'SPassAtt/90'] = (final_gk_stats_filtered['SPassAtt'] / final_gk_stats_filtered['90s']).round(2)\n",
    "final_gk_stats_filtered.loc[:, 'LPassAtt/90'] = (final_gk_stats_filtered['LPassAtt'] / final_gk_stats_filtered['90s']).round(2)\n",
    "final_gk_stats_filtered.loc[:, 'SPassCmp/90'] = (final_gk_stats_filtered['SPassCmp'] / final_gk_stats_filtered['90s']).round(2)\n",
    "final_gk_stats_filtered.loc[:, 'LPassCmp/90'] = (final_gk_stats_filtered['LPassCmp'] / final_gk_stats_filtered['90s']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep for the final output\n",
    "gk_columns_to_keep = [\n",
    "    'ID', 'Player', 'Team', 'Age', 'Nationality', 'Season', 'MV1', 'MV2', 'Position', 'Comp', 'MP', 'Starts', 'Min', '90s',\n",
    "    'GA', 'GA/90', 'SoTA','SoTA/90', 'PSxG-GA', 'PSxG-GA/90', 'Save%',\n",
    "    'CS%','CrossAtt', 'CrossAtt/90', 'CrossStop%','PKAtt', 'PKAtt/90', 'PKSave%',\n",
    "    'ActOutPA', 'ActOutPA/90', 'SPassAtt', 'SPassAtt/90', 'SPassCmp', 'SPassCmp/90',\n",
    "    'LPassAtt', 'LPassAtt/90', 'LPassCmp', 'LPassCmp/90', 'SPass%', 'LPass%', 'PPM', 'On-Off']\n",
    "\n",
    "# Filter the columns to keep\n",
    "final_gk_stats_filtered = final_gk_stats_filtered[gk_columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gk_stats_filtered.to_csv('../data/processed/goalkeepers.csv', index=False)\n",
    "final_out_stats_filtered.to_csv('../data/processed/outfielders.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
